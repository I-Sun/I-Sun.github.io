# Deep learning

---

该篇论文属于综述性论文，主要介绍深度学习相关的主要知识。

论文的第一部分主要是讲述了以下几方面内容

- 机器学习技术和机器学习系统在生活中的具体应用方向

  ```
  机器学习技术的应用方向：
  	互联网搜索、内容过滤
  	电子商务、物品推荐
  	智能相机和智能手机等消费品
  机器学习系统的具体应用：
  	图片分类和识别
  	语音文字转化
  	用户兴趣推荐（新闻）
  	内容检索
  ```

- 传统的机器学习（模式识别技术）系统的实现方式以及面临的弊端

  ```
  传统的机器学习系统受限于非结构化数据的处理
  传统机器学习通常需要非常仔细的特征工程（提取抽象）和相关行业领域的专家的帮助才可以完成数据特征的提取
  ```

- __什么是表示学习，什么是深度学习__

  ```
  这部分内容是第一部分的重点
  表示学习：表示学习是一系列方法的代指，接收原始数据，自动学习（发现）数据的特征表示。
  深度学习：是一种多层非线性表示层组成的表示学习方法。每一层都是对上一次数据特征的进一步抽象。
  ```

- 深度学习克服了传统机器学习在提取复杂数据（非结构化数据）时特征提取困难的问题，实际应用中取得了巨大的成功。

  ```
  主要取得的成功体现在如下几方面：
  	图像识别
  	语音识别
  	药品预测（医学）
  	粒子加速器数据分析（物理）
  	大脑重建
  	基因学
  	自然语言处理
  		主题（话题）分类
  		情感解析
  		问答系统
  		语言翻译
  ```

- 作者们认为深度学习在不久的将来会取得进一步的成功

  ```
  深度学习的特性（优点）：
  	1. 几乎不需要手工提取特征
  	2. 充分利用现实中产生的大量数据和机器计算性能的不断提升
  ```

---

## 监督学习 Supervised learning

- 监督学习是一种最常见的机器学习方式，作者通过图像分类任务为例，阐述了一些监督学习的相关概念（输入数据、目标函数、权重、特征向量、评分向量、权重更新）

- 监督学习系统通过梯度的计算来不断的更新权重

  ```
  向梯度值的反方向不断的跟新权重向量，从而使损失函数（目标函数）最优达到最优值
  ```

- 作者将目标函数（所有样本损失的平均值）想象成一个多维的山地地形。梯度表面了山地中某个点的最陡峭的方向。

- **描述了监督学习中的两个概念：随机梯度下降法、测试集**

  ```
  随机梯度下降法为什么称之为随机？
  	随机梯度下降法在训练集上随机选取小批量的样本数据计算损失函数和梯度，相比于梯度下降法（所有训练集），在计算梯度的过程中随机的产生了噪声数据。原文描述如下：
  It is called stochastic because each small set of examples gives a noisy extimate of the average gradient over all examples.
  ```

- 传统的机器学习算法通常在使用线性分类器对手工提取的特征进行分类，分类面是一个多维空间中的超平面。

- 线性分类器使用一个超平面将特征空间分成两个部分。但是类似于图像或者语音需要克服输入数据中不相干的信息，例如位姿、角度、光照、语音语调的变化。这也说明了一个好的特征提取器对于分类器的重要性。也可以使用核方法，对特征进行非线性分分类。但是传统特征提取方法通常面临很大的困难。通过深度学的的方法可以一般化的解决传统特征提取方法所面临的困难。

  ```
  作者用狼和萨摩亚的分类识别举例，来说明针对于图像语音等复杂的非结构化数据特征提取困难的问题。
  ```

- 采用深度学习技术，通过多层非线性组合，组成了一个非常复杂的函数空间。在特征提取过程中可以同时实现对不重要特征的忽略和对重点特征的提取。

---

## 反向传播 Backpropagation to train multilayer architectures

- 80年代中期，包含多层的网络结构被证明可以使用SGD的方法进行训练优化

- 反向传播算法只不过是对微积分中链式法则的应用。通过图例的方式具体解释了反向传播的过程。

- 前馈神经网络常用的激活函数从sigmoid和tanh逐渐变成了Relu。可以使网络更快的收敛。通过多层隐层的变换，学习到线性可分的特征向量。

- 在上世纪90年代，神经网络和反向传播普遍被机器学习协会所抛弃

  ```
  抛弃原因：
  	1. 被认为无法学习到有效的特征表示在不依赖先验知识的情况下
  	2. 梯度下降法会使网络陷入局部极小值
  ```

- **理论研究及实验结果显示，局部最优解并不是最严重的问题，梯度消失的问题更为严重**

  ```
  研究表明，在网络的非线性空间中存在着大量的鞍点。当训练陷入到鞍点的时候，会影响网络的训练。
  （鞍点本质就是梯度消失的一种表现，会导致很多权重失效，使训练在少量权重组成的多维曲线上进行优化）
  ```

- 2006年，从CIFAR研究小组的提出非监督学习算法开始，科学家关于深度前馈网络的兴趣才开始复苏。

  ```
  作者在这里简要描述了CIFAR是如何进行非监督学习的，暂时没看懂...
  ```

- 最先采用这种预训练的方式是在语音识别领域。

- 引出卷积神经网络

---

## 卷积神经网络 Convolutional neural network

- 简要说明卷积神经网络的作用和特点

  ```
  输入数据的信号维度：
  	1维 序列和信号，主要包含语音信息
  	2维 图像、声音频谱
  	3维 视频信号、立体模型
  卷积神经网络主要用于多维信号的处理
  卷积神经网络的四个关键点：
  	1. 权重共享
  	2. 局部连接
  	3. 池化
  	4. 多层网络结构
  ```

- 用图示举例说明了一个简单的卷积神经网络的结构。

  ```
  卷积神经网络之所以采用这样的结构，主要有以下两个原因：
  	1. 数据通常是局部相关的，局部连接
  	2. 数据的组成方式和所在的位置无关（平移不变性），权值共享
  ```

- **卷积层用来检测局部特征，池化层用来合并局部信息**

  ```
  为什么需要池化层？
  	组成物体的不同部分的相对位置可能会发生微小的变化，池化层可以粗粒度的敏感这种相对变化，检测更具鲁棒性。
  池化层的效果（作用）：
  	降维
  	带来目标特征一定的变化和扭曲的不变性
  通常将2-3个卷积层+激活函数+池化层组成一个基础模块
  ```

- 深度神经网络用来探索这种逐层抽象的数据特征

  ```
  图像领域：
  	edges -> motifs -> parts -> objects
  语音领域：
  	sounds -> phones -> phonemes -> syllables -> words -> sentences
  ```

- **卷积层和池化层来自于诗句神经科学中简单细胞和复杂细胞的经典概念**

- 卷积神经网络早在1990s就已经涌现了大量的应用和研究。

---

## 通过卷积神经网咯进行图像识别 

## Image understanding with deep convolutional network

- 20世纪初期，卷积神经网络在检测、分割、识别方向取得了巨大的成功。特别是在标注数据充足的领域。
- 由于可以对数据进行像素级标注，很多公司开始研发移动机器人和自动驾驶相关方向的技术。也有些公司关注在自然语言理解和语音识别
- 2012年ImageNet比赛之前，卷积神经网络的作用和能力一直被忽略。2012ImageNet比赛的成功主要取决于基于GPU的高效训练、Relu、新的正则化方法Dropout、数据增广。最新的研究将cnn和rnn联合训练，自动产生输入图片的标题。
- 当前卷积神经网络在网络深度和参数量都有了很大的提升，主要得益于计算机硬件的性能的提升、软件和算法并行化训练
- 基于cnn的计算机视觉技术吸引了很多大公司的注意。
- 许多公司正在研究卷积神经网络芯片，支持智能手机、数码相机、机器人、自动驾驶领域的视觉实时计算

---

## 分布式特征表示和自然语言处理

## Distribution representations and language processing

- 相比于传统学习方法，深度学习理论带来了两个指数级优点

  ```
  1. 分布式特征表示提升算法重新组合学过的特征的泛化能力（n个特征可以表示2的n次方物体）
  2. 在深度上的特征组合带来了另外一个指数表达优势
  ```

- 包含多个隐层的神经网络可以从输入数据更好的预测目标数据。

---

## 循环神经网络

## Recurrent neutral networks

---

## 深度学习的未来

## The future of deep learning

- 无监督学习是重新燃起深度学习热潮的催化剂

  ```
  在人和动物的学习中无监督学习占据主导地位
  无监督学习可以进一步分为聚类问题和关联问题
  	聚类问题：希望在在数据中发现内在的分组
  	关联问题：发现数据的各个部分之间的联系
  ```

- 展望计算机视觉的未来

  ```
  期望未来的视觉处理系统具有如下特点
  	端到端训练
  	结合cnn和rnn
  	使用强化学习的方式决定视觉目标的对象
  将深度学习和强化学习结合进行还处于初级阶段，但是相比于被动学习视觉系统，在图像分类任务上已经超越并且在视频游戏智能上取得了令人印象深刻的成果。
  ```

- 自然语言处理在未来也会是主流趋势之一

- 最终人工智能的重大进展将通过将表示学习与复杂推理相结合的系统实现

  ```
  但是需要新的范式来取代基于规则的符号表达式操作，从而可以对大向量（高维数据或复杂数据）进行建模
  ```

---

**扩展**

- 强化学习（Reinforcement learning）

  ```
  强化学习通常用马尔可夫决策过程描述：
  	1. 机器处于环境E中，状态空间为X, 其中每一个状态x(属于X)是机器感知到的环境描述
  	2. 机器能采取的动作构成动作空间A
  	3. 转移函数P将使得环境从当前状态按照某种概率转移东另一个状态
  	4. 转移到另一个状态时，环境会根据潜在得奖赏函数R反馈给机器一个奖赏
  	5. E = <X, A, P, R>
  ```

- GAN网络有两个主要组件：鉴别器和生成器 



